ðŸ‘‰ `jee-neet-rag` â€” your **AI-Powered JEE/NEET Tutor using RAG + Google Gemini**.

This version includes everything:

* Overview of what the project *does*
* Detailed local setup (backend + frontend)
* API explanation
* RAG architecture diagram (in text form)
* Contribution guide
* Deployment & environment setup
* And best practices

You can copy this directly into your `jee-neet-rag/README.md` file ðŸ‘‡

---

# ðŸ“š JEE/NEET AI Tutor â€” RAG + Google Gemini

> ðŸ§  An AI-powered tutoring platform built using **Retrieval-Augmented Generation (RAG)** and **Google Gemini API** to help students prepare for **JEE** and **NEET** by answering questions using real NCERT and past paper data.

---

## ðŸš€ Overview

**JEE-NEET-RAG** is a full-stack project that combines **AI + Search + Education**.
It lets students ask questions (theory or numerical) from their syllabus, and the AI answers them with **step-by-step reasoning** based on **NCERT content** and **past paper data**.

The backend uses:

* **FastAPI** + **FAISS** + **Sentence Transformers** for the RAG pipeline.
  The frontend uses:
* **React**, **TailwindCSS**, and **Framer Motion** for a modern chat interface.

The AI model is:

* **Google Gemini 1.5 Flash** â€” free, fast, and intelligent.

---

## ðŸ§  What the Project Does

Hereâ€™s how the system works behind the scenes ðŸ‘‡

### ðŸ§© Retrieval-Augmented Generation (RAG) Pipeline

```
1ï¸âƒ£ User asks a question (e.g., "Explain Bohrâ€™s model of atom")
2ï¸âƒ£ The system retrieves the most relevant text chunks from NCERT using FAISS
3ï¸âƒ£ Combines those chunks into a contextual prompt
4ï¸âƒ£ Sends the context + question to the Gemini model
5ï¸âƒ£ Gemini generates a step-by-step, syllabus-accurate explanation
6ï¸âƒ£ Response is displayed beautifully on the frontend
```

This ensures **accurate, syllabus-based** answers instead of random LLM responses.

---

## âš™ï¸ Features

- **RAG Pipeline** â€” retrieves context from NCERT and past paper data
- **AI Tutor Chatbot** â€” Chat-style interface for question-answering
- **Gemini API** â€” Uses Googleâ€™s free Gemini API (no OpenAI key required)
- **FAISS Vector DB** â€” Efficient and local semantic search
- **React UI** â€” Modern, mobile-friendly chat design
- **Environment-based config** â€” Works locally or in production easily
- **Easy Dataset Expansion** â€” Just drop `.txt` files to add new chapters

---

## ðŸ§° Tech Stack

| Layer          | Technology                                          |
| -------------- | --------------------------------------------------- |
| **Frontend**   | React, TailwindCSS, Framer Motion, Lucide Icons     |
| **Backend**    | FastAPI, Uvicorn, Python 3.10+                      |
| **AI Model**   | Google Gemini 1.5 Flash (Free via Google AI Studio) |
| **Vector DB**  | FAISS                                               |
| **Embeddings** | Sentence Transformers (`all-MiniLM-L6-v2`)          |
| **Data**       | NCERT + JEE/NEET past papers (as text files)        |

---

## ðŸ› ï¸ Local Setup Guide

### ðŸ§© 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/kalim-Asim/jee-neet-rag.git
cd jee-neet-rag
```

---

### ðŸ§© 2ï¸âƒ£ Backend Setup

#### Create a virtual environment

```bash
cd backend
python -m venv .venv
.venv\Scripts\activate     # (on Windows)
```

#### Install dependencies

```bash
pip install -r requirements.txt
```

#### `requirements.txt`

```text
fastapi
uvicorn[standard]
sentence-transformers
faiss-cpu
google-generativeai
python-dotenv
pydantic
tqdm
```

#### Create `.env` file inside `backend/`

```ini
GOOGLE_API_KEY=your_google_api_key_here
GEMINI_MODEL=models/gemini-2.5-pro
FAISS_INDEX_PATH=data/embeddings/faiss_index.idx
ID_MAP_PATH=data/embeddings/id_to_text.pkl
EMBEDDING_MODEL=all-MiniLM-L6-v2
HOST=0.0.0.0
PORT=8000
```

> ðŸŽ¯ Get your free API key from:
> [https://aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey)

---

### ðŸ§© 3ï¸âƒ£ Prepare Data for RAG

Create folders:

```
jee-neet-rag/data/ncert/
```

Add `.txt` files:

```
data/ncert/physics_ch1.txt
data/ncert/chemistry_ch1.txt
```

Each file should contain plain text (you can copy content from NCERT PDFs).

---

### ðŸ§© 4ï¸âƒ£ Generate FAISS Embeddings

Run:

```bash
python rag/ingest.py
```

Youâ€™ll see:

```
Embedding 120 chunks with all-MiniLM-L6-v2 ...
Building FAISS index...
Saving index -> data/embeddings/faiss_index.idx
Saving id->text map -> data/embeddings/id_to_text.pkl
Done.
```

---

### ðŸ§© 5ï¸âƒ£ Start Backend

Run from project root (`jee-neet-rag/`):

```bash
uvicorn backend.api.main:app --reload --host 0.0.0.0 --port 8000
```

Now open the API docs:
ðŸ‘‰ [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

---

### ðŸ§© 6ï¸âƒ£ Frontend Setup

Open a new terminal:

```bash
cd frontend
npm install --legacy-peer-deps
npm install framer-motion lucide-react better-react-mathjax
npm run dev
```

Open in browser:
ðŸ‘‰ [http://localhost:5173](http://localhost:5173)

---

## ðŸ“¦ Folder Structure

```
jee-neet-rag/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â””â”€â”€ routes/chat.py
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ ingest.py
â”‚   â”‚   â”œâ”€â”€ retriever.py
â”‚   â”‚   â””â”€â”€ merge_embeddings.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ gemini_llm.py
â”‚   â””â”€â”€ config.py
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatBox.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Message.jsx
â”‚   â”‚   â”‚   â””â”€â”€ Loader.jsx
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ data/ncert/
â”‚   â”œâ”€â”€ physics_ch1.txt
â”‚   â”œâ”€â”€ chemistry_ch1.txt
â””â”€â”€ README.md
```

---

## ðŸŒ API Endpoints

### `/api/chat` â†’ POST

**Description:** Accepts a query and returns a context-based AI-generated answer.

#### Example Request

```json
{
  "query": "Explain Bohr's model of hydrogen atom."
}
```

#### Example Response

```json
{
  "answer": "According to Bohr's model, electrons revolve in discrete orbits..."
}
```

---

## ðŸ§  RAG Flow Diagram (Text Form)

```
User Question
   â†“
Sentence Transformer â†’ Embedding Vector
   â†“
FAISS â†’ Retrieve top 5 relevant chunks
   â†“
Combine context + question â†’ Prompt
   â†“
Gemini Model â†’ Generate Answer
   â†“
Frontend â†’ Display Chat Response
```

---

## â˜ï¸ Deployment Guide

### ðŸŸ¢ Deploy Backend (Render)

* Go to [https://render.com](https://render.com)
* Create a new **Web Service**
* Connect your GitHub repo
* Add Environment Variables:

  ```
  GEMINI_API_KEY=your_google_api_key_here
  GEMINI_MODEL=gemini-1.5-flash
  ```

### ðŸŸ£ Deploy Frontend (Vercel)

* Go to [https://vercel.com](https://vercel.com)
* Import the repo
* Add:

  ```
  VITE_API_URL=https://your-backend.onrender.com
  ```
* Deploy ðŸš€

---


## ðŸŒŸ Demo Preview (Example)

**Question:**

> â€œExplain Bohrâ€™s model of the hydrogen atom.â€

**Answer (AI):**

> According to Niels Bohr, electrons revolve around the nucleus in stable orbits.
> The angular momentum is quantized as
> ( mvr = n \frac{h}{2\pi} ).
> Energy levels are given by ( E_n = -13.6/n^2 \text{ eV} ).
> Transitions between levels emit or absorb photons.

---

